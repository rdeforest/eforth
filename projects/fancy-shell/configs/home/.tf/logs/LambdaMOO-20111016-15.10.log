                          ***************************
                          *  Welcome to LambdaMOO!  *
                          ***************************
                                       
                     Running Version 1.8.3+47 of LambdaMOO

PLEASE NOTE:
   LambdaMOO is a new kind of society, where thousands of people voluntarily
come together from all over the world.  What these people say or do may not
always be to your liking; as when visiting any international city, it is wise
to be careful who you associate with and what you say.
   The operators of LambdaMOO have provided the materials for the buildings of
this community, but are not responsible for what is said or done in them.  In
particular, you must assume responsibility if you permit minors or others to
access LambdaMOO through your facilities.  The statements and viewpoints
expressed here are not necessarily those of the wizards, Pavel Curtis,
or Roger Crew, and those parties disclaim any responsibility for them.

NOTICE FOR JOURNALISTS AND RESEARCHERS:
  The citizens of LambdaMOO request that you ask for permission from all
direct participants before quoting any material collected here.

For assistance either now or later, type `help'.
The lag is low; there are 53 connected.
*** Connected ***
Storage room
Boxes, crates, scraps of stuff, and a dead rat are strewn about this small room. The air and everything else are dusty. Cough, cough. A hammock has been strung between two walls, and a single 60 watt bulb casts a dim light about the place.
There is new activity on the following lists:
    *Server-Hackers (#24451)             14 new messages
    *Core-DB-Issues (#8175)              4 new messages
    *Site-Issues (#72243)                1 new message
Last connected Thu Sep 22 09:11:32 2011 PDT from ICE-X-FW-PAT.FHCRC.ORG
=> #58746  (Crag)
[used 2 ticks, 0 seconds.]
< connected: Crag. Total: 54 >
Message 1141 on *Server-Hackers (#24451):
Date:     Tue Apr 20 15:47:12 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)

> OK.  I thought, given that things like listconcat() already involve
> a malloc and an O(n) walk over list elements, involving a couple of
> function calls each, that summing up the size of each element as you
> go along would not be too much more expensive. 

*IF* the sizes are already cached so that we're not having to descend into each element, AND there's a reasonable story for where the cached values live and how they get there, then, yes, it shouldn't be that big a deal, 

Though we still need to pay *some* attention to that constant factor, and I do worry a bit about all of the list/string munging that happens in the server outside of user code (and still uses Vars and a lot of the same machinery for manipulating them, e.g., the verb code parser).  Doing size-accounting for values that do NOT ultimately end up in userspace will be a complete waste of time.

> Var would have a field that holds the size.  

No.  You really want it next to the refcount (i.e., at the far end of the .str/.list pointer), not in the Var.  New fields in the Var struct would expand *all* kinds of values, numbers, errors, objects,...; bad news.  MEMO_STRLEN is currently my model for the Right way to do this.

> Does this sound (relatively) expensive?

Oddly enough, apart from the aforementioned worry, no, but my saying that off the top of my head doesn't really mean a whole lot.  Some experimentation will be needed.  

I'm also wondering more about the current status of MEMO_STRLEN, i.e., whether its not being turned on by default is a matter of

(1) not being quite ready for prime time
(2) tested/benchmarked AND NOT actually worth it after all, 
    for some reason, or
(3) tested/not-benchmarked, possibly worth it,
    but nobody knows for sure,
    and nobody wanted to mess with the status quo.

(I've been assuming (3), but...)
--------------------------
Message 1142 on *Server-Hackers (#24451):
Date:     Wed Apr 21 16:16:10 2010 PDT
From:     Xeric (#112019)
To:       *Server-Hackers (#24451)

I implemented MEMO_STRLEN for jitmoo, where the resulting "pascal-style" strings were a boon to inlined range checking.  It turns out there is a performance advantage to having it around all the time, so I checked it in to CVS.  I just left it off by default to be conservative.  It's not critical for correctness or performance (given the speed of today's machines and the relatively modest size of MOOs these days).  If someone was using a patch or extension to MOO that didn't honor the string contracts exactly the MEMO_STRLEN option could cause them problems.
--------------------------
Message 1143 on *Server-Hackers (#24451):
Date:     Wed Apr 21 20:00:11 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)

>  It turns out there is a performance advantage to having 
>  [MEMO_STRLEN] around all the time, so I checked it in to CVS.

ok then.  It's on for the next build.  Wheee....
--------------------------
Message 1144 on *Server-Hackers (#24451):
Date:     Wed Apr 21 20:19:44 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)

>  >  It turns out there is a performance advantage to having
>  >  [MEMO_STRLEN] around all the time, so I checked it in to CVS.
>  
>  ok then.  It's on for the next build.  Wheee....

;{server_version("options/MEMO_STRLEN"),server_version("make/CFLAGS")}
=> {{0}, "-O2"}

Enjoy.
--------------------------
Message 1145 on *Server-Hackers (#24451):
Date:     Thu Apr 22 23:46:34 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)

>  ;{server_version("options/MEMO_STRLEN"),server_version("make/CFLAGS")}
>  => {{0}, "-O2"}

Current verdict seems to be that it was a stupid idea to be trying *both* of these at once.

;{server_version("options/MEMO_STRLEN"),`server_version("make/CFLAGS") ! ANY'}
=> {{0}, E_INVARG}

oh, and, for those of you who were wondering, for those options that are #defined and the actual value does not matter, #defined shows up as {0} (true) and #undef shows up as #-1 (false) -- the idea being that these won't be confused with any actual setting to a particular string or number.  (Hm.  Now I'm wondering if I should have used {1} and #0 ...?)
--------------------------
=> #0  (The System Object)
[used 2 ticks, 0 seconds.]
Message 1147 on *Server-Hackers (#24451):
Date:     Tue Apr 27 08:50:18 2010 PDT
From:     kirlan (#74469)
To:       *Server-Hackers (#24451)

While we're blowing the dust off the server code, is there any chance of fixing up and incorporating one of the associative array patches?  The one on launchpad purportedly has a serious crash bug, but one hopes it's fixable.  Yes, there's waifs, but I wouldn't mind having something that obeys the copy-on-write semantics of lists.
--------------------------
Message 1148 on *Server-Hackers (#24451):
Date:     Thu Apr 29 15:42:09 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)
Subject:  okay, let's just leave MEMO_STRLEN off, then

admittedly, to be fair, the proximate cause of today's silliness was evidently a broken pipe (SIG_PIPE) 

#2  0x08067319 in push_output (h=0xdb6c1c0) at net_multi.c:241
#3  0x08067375 in close_nhandle (h=0xffffffe0) at net_multi.c:342
#4  0x08068034 in network_process_io (timeout=0) at net_multi.c:601
#5  0x08074005 in main (argc=Cannot access memory at address 0x0

which is NOT the sort of thing I'd expect from MEMO_STRLEN failing and *may* simply have been a matter of having the debugger attached messing up the signal handling.  (at the moment, I'm *very* unclear on why output is being pushed on closed network handles after a write has failed; so there may be a real bug there after all, we'll see...)
--------------------------
Message 1149 on *Server-Hackers (#24451):
Date:     Thu May  6 17:14:24 2010 PDT
From:     Rog (#4292)
To:       *Server-Hackers (#24451)
Subject:  source code

For those of you who've been asking about current server sources, the current state of what LambdaMOO is running is available at

   http://github.com/wrog/lambdamoo

And yes, I've now switched over to using git (thus getting myself up to date w.r.t. what all of the other server hacking folks did two years ago... ok, I'm slow...), and this is my own public repository.  While the lambdamoo CVS tree at sourceforge has been (mostly) brought up to date, I don't know how much longer I'll be able to do that and stay sane (and it's kind of stupid to be committing the same sets of changes twice...), so it's a fair bet that the SF CVS tree's days are numbered, though *exactly* what we're doing about that is still in flux.

FYI:  Other repositories out there that I know about:

   http://codepoint.the-b.org/gitweb/*  (unicode MOO project)
   http://github.com/xythian/wp-lambdamoo  (Waterpoint server sources)
--------------------------
Message 1150 on *Server-Hackers (#24451):
Date:     Wed May 19 05:14:16 2010 PDT
From:     Biafra (#61504)
To:       *Server-Hackers (#24451)
Subject:  moo.mud.org

Sorry to post in this folder, but can't get answers from hostmaster@mud.org (or host-master). If some one can forward me to a better contact TIA.
--------------------------
Message 1151 on *Server-Hackers (#24451):
Date:     Mon Dec 27 13:51:56 2010 PST
From:     ryans (#124002)
To:       *ProgrammersQ&A (#6556)
Subject:  C Extension
Resent-By:     Blackbriar (#30119)
Resent-To:     *Server-Hackers (#24451)
Original-Date: Mon Dec 27 12:38:04 2010 PST

Hello All,
I am currently running a MOO, and would like people to be able to switch players without disconnecting. (For example, I could call switch_connection(#Current_Player, #New_Player). I have very little experience with C and writing MOO extensions, but have lots with MOO (I'm running LambdaServer), and I have no idea why it isn't working. Here is some sample output:
;switch_connection(me, #9283);
*** Connected ***
generic room
You see nothing special.
I know that at least somewhat worked, because my wizard character was in another room then this player character #9283, who was in a generic room.  When I type in future things, like ;me.name, nothing else is outputted to me. When I disconnect, and try to re-connect again, it connects successfully, however no welcome/login screen is outputted.
Here is my extension code:
static package
bf_switch_connection(Var arglist, Byte next, void *vdata, Objid progr)
{
player_connected(arglist.v.list[1].v.obj, arglist.v.list[2].v.obj, 0);
free_var(arglist);
return no_var_pack();
}
Just so you know, player_connected() is defined in server.h.

I know there are some really smart people on here, and I really appreciate any and all help someone could give me on fixing this.

Thank you so much in advance!
--------------------------
Message 1152 on *Server-Hackers (#24451):
Date:     Wed Aug 17 10:14:45 2011 PDT
From:     Diopter (#98842)
To:       *Server-Hackers (#24451)

Saw this on the MOO-Talk list. Does the current version of the server not save tasks that are doing a read()?

| Date: Wednesday, August 17, 2011 7:21 AM
| From: "Todd Sundsted" <todd.sundsted@gmail.com>
| To: "MOO Talk" <MOO-talk@googlegroups.com>
| 
| One surprising limitation of the original LambdaMOO server is that
| tasks that are suspended while in `read()' are not dumped to the on-
| disk database.  This kind of makes sense in the context of how
| LambdaMOO was used originally, but is surprising none the less.  If
| you do a lengthy calculation, call `read()' for input, and the
| database dumps, that task and the *entire calculation* is gone if/when
| the dumped database is loaded again.  Tasks that call `suspend()' on
| the other hand, are saved/restored.
--------------------------
Message 1153 on *Server-Hackers (#24451):
Date:     Wed Aug 17 10:23:02 2011 PDT
From:     Blackbriar (#30119)
To:       Diopter (#98842) and *Server-Hackers (#24451)

>  Saw this on the MOO-Talk list. Does the current version of the
>  server not save tasks that are doing a read()?

What -should- be the desired behavior, for a database dump during a read()?

(The player connection won't be there when the server restarts anyway.)
--------------------------
Message 1155 on *Server-Hackers (#24451):
Date:     Wed Aug 17 11:11:05 2011 PDT
From:     Diopter (#98842)
To:       *Server-Hackers (#24451)

I would hope that the task's state would be saved, and when the server is restarted, the read()s should all return E_INVARG (as they currently do if the player disconnects or the network connection dies).  I'm worried about the situation where MOO code sets up some state and then does a read(), including a read() from a network connection, and then has its task vaporized upon restarting from a checkpoint, thus leaving dregs around.  Of course, MOO code should be written defensively and should take into account the case that a previous task was terminated without having been able to clean up, but why should the server make things more difficult?
--------------------------
Message 1156 on *Server-Hackers (#24451):
Date:     Thu Aug 25 12:36:39 2011 PDT
From:     Xeric (#112019)
To:       *Server-Hackers (#24451)

Seems reasonable to me that they should dump and on reload immediately act like they were disconnected.  I never noticed this before but it might explain why I occasionally saw orphaned NNTP server objects.
--------------------------
Message 5123 on *Core-DB-Issues (#8175):
Date:     Wed Apr 20 13:57:27 2011 PDT
From:     jeremiah (#119870)
To:       *Core-DB-Issues (#8175)
Subject:  $list_utils:make(LARGE INTEGER) seems to crash MOOs

Calling, e.g. $list_utils:make(1000000) seems to exhaust RAM faster than ticks.
A cap on the size of the integer that can be passed to $list_utils:make() might be one (heavy-handed) approach to protecting against this scenario.
--------------------------
Message 5124 on *Core-DB-Issues (#8175):
Date:     Wed Apr 20 14:48:48 2011 PDT
From:     Diopter (#98842)
To:       *Core-DB-Issues (#8175)
Subject:  Re: $list_utils:make(LARGE INTEGER) seems to crash MOOs

If you grab Rog's server code from about a year ago (@peek 1137 on *server), you can create a $server_options.max_list_concat property, which will limit the length of lists.  Even if you don't run the new server, you could create that $server_options property and have $list_utils:make check its value.
--------------------------
Message 5125 on *Core-DB-Issues (#8175):
Date:     Sun Sep  4 16:37:27 2011 PDT
From:     Sleeper (#98232)
To:       *Core-DB-Issues (#8175) and Sleeper (#98232)
Subject:  $housekeeper

[Sent this to *wiz, tehn realized some of it was appropriate for *core]



1) bogus bin in $housekeeper.recycle_bins

>;#36830.recycle_bins  => {#5000, #6565, #4455}
>#6565 => #6565  (Treasure Chest Feature Object)

Suggesting:
> ;#36830.recycle_bins={#5000, #4455}


2) $housekeeper:continuous() seems to not be running

>#36830.task=> 500492341
>;$code_utils:task_valid($housekeeper.task)=> 0

(plus lots of object not in the right place)

Suggesting:
> ;$housekeeper:continuous()


3) <invalid> in $housekeeper.requestors causes tracebacks 

>;here=> #16563  (Housekeeper's quarters)
>cleanup-list all
[...]
#36830:cleanup_list, line 25:  Invalid indirection
... called from #16563:cleanup-list, line 2
(End of traceback)

>;#38064  in $housekeeper.clean=> 287
>; $housekeeper.requestors[287]=> #53118  <invalid>
>clean? #38064
#36830:is_cleaning, line 7:  Invalid indirection
... called from #16563:clean?, line 6
(End of traceback)

Suggesting:
Protect .prop references to raw object numbers.

a)  line 20 of $housekeeper:replace() changed from
       requestor = this.requestors[i];
    to
       requestor = $recycler:valid(tr=this.requestors[i]) ? tr | $no_one;

b)  line 18 of $housekeeper:cleanup_list() changed from
       req = reqs[i];
    to
       req = $recycler:valid(tr=req[i]) ? tr | $no_one;

c)  line 25 of $housekeeper:cleanup_list() changed from
       player:tell($string_utils:left(tostr(ob), objfieldwid), $string_utils:left(ob.name, 26), "=>", $string_utils:left(tostr(place), objfieldwid), place.name || "nowhere", " (", req.name, ")");
    to
       player:tell($string_utils:left(tostr(ob), objfieldwid), $string_utils:left(ob.name, 26), "=>", $string_utils:left(tostr(place), objfieldwid), (valid(place) ? place.name | "nowhere") || "nowhere", " (", req.name, ")");

d)  line 38 of $housekeeper:add_cleanup() changed from
       return tostr(this.requestors[i].name, " already asked that ", what.name, " be kept at ", this.destination[i].name, "!");
    to
       return tostr($recycler:valid(tr=this.requestors[i]) ? tr.name | "Someone", " already asked that ", what.name, " be kept at ", this.destination[i].name, "!");

e)  line 7 of $housekeeper:is_cleaning changed from
       return tostr(cleanable.name, " is kept tidy at ", info[1].name, " (", info[1], ") at ", info[2].name, "'s request.");
    to
       return tostr(cleanable.name, " is kept tidy at ", $string_utils:nn(info[1]), " at the request of ", $string_utils:nn(info[2]), ".");



4)  Recyclables, <invalids> and other non-players in $housekeeper.requestors

>;;for r in (#36830.requestors) if (!valid(r)) player:tell(r, " is <invalid>"); elseif (!$recycler:valid(r)) player:tell(r, " is not Rvalid"); elseif (!is_player(r)) player:tell(r, " non-player"); endif endfor
#120663 non-player
#58826 is not Rvalid
#53118 is <invalid>
#12856 non-player
#12856 non-player
#33558 is not Rvalid
#33558 is not Rvalid
#33558 is not Rvalid
#33558 is not Rvalid
#33558 is not Rvalid
#33558 is not Rvalid

Suggesting:
$housekeeper:replace() is already garbage collecting, extend gc to remove entries with bad .requestors.
(:replace is called by :continuous over the entire cleanup list)

Change
 8:  if (!($recycler:valid(object) && ($recycler:valid(place) || place == #-1) && !(object.location in this.recycle_bins)))
 9:    "object no longer valid (recycled or something), remove it.";
to 
 8:  if (!($recycler:valid(object) && ($recycler:valid(r=this.requestors[i]) && is_player(r)) && ($recycler:valid(place) || place == #-1) && !(object.location in this.recycle_bins)))
 9:    "object or requestor no longer valid (recycled or something), remove entry.";




-Sleeper

--------------------------
Message 5126 on *Core-DB-Issues (#8175):
Date:     Fri Sep  9 12:44:32 2011 PDT
From:     Sleeper (#98232)
To:       *Core-DB-Issues (#8175)
Subject:  more $housekeeper

$housekeeper:replace has gotten a fork added to it.  Current theory is that someone with kill_task(task_id()) in their exitfunc/moveto was killing off the Housekeeper's task.

Also note the changes in 3) b) in 5125 on *core had a typo, and should have been:

---
b)  line 18 of $housekeeper:cleanup_list() changed from
       req = reqs[i];
    to
       req = $recycler:valid(tr=reqs[i]) ? tr | $no_one;
                                   ^
---


Happy Housekeeping

--------------------------
Message 71 on *Site-Issues (#72243):
Date:     Wed Jun  1 14:19:38 2011 PDT
From:     Rog (#4292)
To:       *Site-Issues (#72243)
Subject:  new box

(...wow, have I really not posted here in 4 years?  Hopefully you all know about http://lambdamoo.blogspot.com for news about such outages as I can predict in advance and the general state of the world...)

Anyway, I've updated @version to know about the new box.  Wheee.

--------------------------
The MOO is currently running version 1.8.3+47 of the LambdaMOO server code on a four processor 3.1GHz Intel Core i3-2100 with 6GB RAM, running Debian 6.0 (squeeze) and version 2.6.32 of the Linux kernel.
The database was created from scratch.
No News (is good news)
